{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: Yi-Chun Hung\n",
    "\n",
    "Student ID: 103061145"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download the dataset provided in this [link](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#). The sentiment dataset contains a `sentence` and `score` label. Read what the dataset is about on the link provided before you start exploring it. \n",
    "\n",
    "\n",
    "- Then, you are asked to apply each of the data exploration and data operation techniques learned in the [first lab session](https://goo.gl/Sg4FS1) on the new dataset. You don't need to explain all the procedures as we did in the notebook, but you are expected to provide some **minimal comments** explaining your code. You are also expected to use the same libraries used in the first lab session. You are allowed to use and modify the `helper` functions we provided in the first lab session or create your own. Also, be aware that the helper functions may need modification as you are dealing with a completely different dataset. This part is worth 80% of your grade!\n",
    "\n",
    "\n",
    "- After you have completed the operations, you should attempt the **bonus exercises** provided in the [notebook](https://goo.gl/Sg4FS1) we used for the first lab session. There are six (6) additional exercises; attempt them all, as it is part of your grade (10%). \n",
    "\n",
    "\n",
    "- You are also expected to tidy up your notebook and attempt new data operations that you have learned so far in the Data Mining course. Surprise us! This segment is worth 10% of your grade.\n",
    "\n",
    "\n",
    "- After completing all the above tasks, you are free to remove this header block and submit your assignment following the guide provided in the `README.md` file of the assignment's [repository](https://github.com/omarsar/data_mining_hw_1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sklearn.utils\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# my functions\n",
    "import helpers.data_mining_helpers as dmh\n",
    "import helpers.text_analysis as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"./sentiment labelled sentences\"\n",
    "data_array = []\n",
    "categories = []\n",
    "for filepath in glob.glob(os.path.join(path, '*labelled.txt')):\n",
    "    filename = os.path.splitext(filepath.split(\"/\")[-1])[0]\n",
    "    categories.append(filename)\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            l = line.rstrip().split(\"\\t\")\n",
    "            l.append(filename)\n",
    "            data_array.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_array, columns=['text', 'label', 'category_name'])\n",
    "\n",
    "# Shuffle the entire dataframe\n",
    "df = sklearn.utils.shuffle(df).reset_index(drop=True)\n",
    "\n",
    "# Format of df\n",
    "#   text label from\n",
    "# 1  a     1    c\n",
    "# 2  b     0    a\n",
    "# 3\n",
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length is 3000\n"
     ]
    }
   ],
   "source": [
    "# Print the length of df\n",
    "print(\"Data length is {}\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=3000, step=1)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 0\n",
    "df.iat[0,0] # get the element at both first col and first row\n",
    "df.axes[0] # Show the axis of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text             (The amoung of missing records is: , 0)\n",
      "label            (The amoung of missing records is: , 0)\n",
      "category_name    (The amoung of missing records is: , 0)\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check for the missing value\n",
    "print(df.isnull().apply(lambda x: dmh.check_missing_values(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       (The amoung of missing records is: , 0)\n",
       "1       (The amoung of missing records is: , 0)\n",
       "2       (The amoung of missing records is: , 0)\n",
       "3       (The amoung of missing records is: , 0)\n",
       "4       (The amoung of missing records is: , 0)\n",
       "5       (The amoung of missing records is: , 0)\n",
       "6       (The amoung of missing records is: , 0)\n",
       "7       (The amoung of missing records is: , 0)\n",
       "8       (The amoung of missing records is: , 0)\n",
       "9       (The amoung of missing records is: , 0)\n",
       "10      (The amoung of missing records is: , 0)\n",
       "11      (The amoung of missing records is: , 0)\n",
       "12      (The amoung of missing records is: , 0)\n",
       "13      (The amoung of missing records is: , 0)\n",
       "14      (The amoung of missing records is: , 0)\n",
       "15      (The amoung of missing records is: , 0)\n",
       "16      (The amoung of missing records is: , 0)\n",
       "17      (The amoung of missing records is: , 0)\n",
       "18      (The amoung of missing records is: , 0)\n",
       "19      (The amoung of missing records is: , 0)\n",
       "20      (The amoung of missing records is: , 0)\n",
       "21      (The amoung of missing records is: , 0)\n",
       "22      (The amoung of missing records is: , 0)\n",
       "23      (The amoung of missing records is: , 0)\n",
       "24      (The amoung of missing records is: , 0)\n",
       "25      (The amoung of missing records is: , 0)\n",
       "26      (The amoung of missing records is: , 0)\n",
       "27      (The amoung of missing records is: , 0)\n",
       "28      (The amoung of missing records is: , 0)\n",
       "29      (The amoung of missing records is: , 0)\n",
       "                         ...                   \n",
       "2970    (The amoung of missing records is: , 0)\n",
       "2971    (The amoung of missing records is: , 0)\n",
       "2972    (The amoung of missing records is: , 0)\n",
       "2973    (The amoung of missing records is: , 0)\n",
       "2974    (The amoung of missing records is: , 0)\n",
       "2975    (The amoung of missing records is: , 0)\n",
       "2976    (The amoung of missing records is: , 0)\n",
       "2977    (The amoung of missing records is: , 0)\n",
       "2978    (The amoung of missing records is: , 0)\n",
       "2979    (The amoung of missing records is: , 0)\n",
       "2980    (The amoung of missing records is: , 0)\n",
       "2981    (The amoung of missing records is: , 0)\n",
       "2982    (The amoung of missing records is: , 0)\n",
       "2983    (The amoung of missing records is: , 0)\n",
       "2984    (The amoung of missing records is: , 0)\n",
       "2985    (The amoung of missing records is: , 0)\n",
       "2986    (The amoung of missing records is: , 0)\n",
       "2987    (The amoung of missing records is: , 0)\n",
       "2988    (The amoung of missing records is: , 0)\n",
       "2989    (The amoung of missing records is: , 0)\n",
       "2990    (The amoung of missing records is: , 0)\n",
       "2991    (The amoung of missing records is: , 0)\n",
       "2992    (The amoung of missing records is: , 0)\n",
       "2993    (The amoung of missing records is: , 0)\n",
       "2994    (The amoung of missing records is: , 0)\n",
       "2995    (The amoung of missing records is: , 0)\n",
       "2996    (The amoung of missing records is: , 0)\n",
       "2997    (The amoung of missing records is: , 0)\n",
       "2998    (The amoung of missing records is: , 0)\n",
       "2999    (The amoung of missing records is: , 0)\n",
       "dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 1\n",
    "df.isnull().apply(lambda x: dmh.check_missing_values(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data duplicates number : 17\n",
      "Data length(drop duplicates): 2983\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicated data\n",
    "print(\"Data duplicates number : {}\".format(sum(df.duplicated(\"text\"))))\n",
    "if sum(df.duplicated(\"text\")) > 0:\n",
    "    df.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "print(\"Data length(drop duplicates): {}\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of sample df : 746\n"
     ]
    }
   ],
   "source": [
    "# Sample the data\n",
    "df_sample = df.sample(frac=0.25).reset_index(drop=True)\n",
    "print(\"length of sample df : {}\".format(len(df_sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text label  category_name\n",
      "0                Now this dish was quite flavourful.     1  yelp_labelled\n",
      "1  Everything about this film is simply incredibl...     1  imdb_labelled\n",
      "2              My first visit to Hiro was a delight!     1  yelp_labelled\n",
      "3         Hands down my favorite Italian restaurant!     1  yelp_labelled\n"
     ]
    }
   ],
   "source": [
    "print(df_sample[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visulize the sample data\n",
    "df_category_counts = ta.get_tokens_and_frequency(list(df.category_name))\n",
    "df_sample_category_counts = ta.get_tokens_and_frequency(\n",
    "    list(df_sample.category_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~YiChunHung/82.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(ta.plot_word_frequency(df_category_counts, \"Category distribution\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#py.iplot(ta.plot_word_frequency(df_sample_category_counts, \"Category distribution\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~YiChunHung/84.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 2\n",
    "import plotly.graph_objs as go\n",
    "layout = go.Layout(\n",
    "    barmode='group'\n",
    ")\n",
    "data1 = go.Bar(\n",
    "    x=list(df_category_counts[0]),\n",
    "    y=list(df_category_counts[1]),\n",
    "    name='Category stat'\n",
    ")\n",
    "data2 = go.Bar(\n",
    "    x=list(df_sample_category_counts[0]),\n",
    "    y=list(df_sample_category_counts[1]),\n",
    "    name='Category sample stat'\n",
    ")\n",
    "data = [data1,data2]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature creation\n",
    "df[\"unigrams\"] = df[\"text\"].apply(lambda x: dmh.tokenize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [I, got, food, poisoning, here, at, the, buffe...\n",
       "1        [Always, a, great, time, at, Dos, Gringos, !]\n",
       "2    [It, holds, a, charge, for, a, long, time, ,, ...\n",
       "3                         [It, was, probably, dirt, .]\n",
       "Name: unigrams, dtype: object"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:4][\"unigrams\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all', 'things', 'considered', 'job', 'very', 'well', 'done']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature subset selection\n",
    "count_vect = CountVectorizer()\n",
    "df_counts = count_vect.fit_transform(df.text)\n",
    "analyze = count_vect.build_analyzer()\n",
    "analyze(\" \".join(list(df[4:5].text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '10', '100', '11', '12', '13', '15', '15g', '15pm', '17']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can obtain the feature names of the vectorizer, i.e., the terms\n",
    "count_vect.get_feature_names()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category_name</th>\n",
       "      <th>unigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I got food poisoning here at the buffet.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp_labelled</td>\n",
       "      <td>[I, got, food, poisoning, here, at, the, buffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Always a great time at Dos Gringos!</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp_labelled</td>\n",
       "      <td>[Always, a, great, time, at, Dos, Gringos, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It holds a charge for a long time, is reasonab...</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon_cells_labelled</td>\n",
       "      <td>[It, holds, a, charge, for, a, long, time, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was probably dirt.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp_labelled</td>\n",
       "      <td>[It, was, probably, dirt, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All things considered, a job very well done.</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb_labelled</td>\n",
       "      <td>[All, things, considered, ,, a, job, very, wel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  \\\n",
       "0           I got food poisoning here at the buffet.     0   \n",
       "1                Always a great time at Dos Gringos!     1   \n",
       "2  It holds a charge for a long time, is reasonab...     1   \n",
       "3                              It was probably dirt.     0   \n",
       "4     All things considered, a job very well done.       1   \n",
       "\n",
       "           category_name                                           unigrams  \n",
       "0          yelp_labelled  [I, got, food, poisoning, here, at, the, buffe...  \n",
       "1          yelp_labelled      [Always, a, great, time, at, Dos, Gringos, !]  \n",
       "2  amazon_cells_labelled  [It, holds, a, charge, for, a, long, time, ,, ...  \n",
       "3          yelp_labelled                       [It, was, probably, dirt, .]  \n",
       "4          imdb_labelled  [All, things, considered, ,, a, job, very, wel...  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~YiChunHung/86.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_x = [\"term_\"+str(i) for i in count_vect.get_feature_names()[0:20]]\n",
    "plot_y = [\"doc_\"+ str(i) for i in list(df.index)[0:20]]\n",
    "plot_z = df_counts[0:20, 0:20].toarray()\n",
    "py.iplot(ta.plot_heat_map(plot_x, plot_y, plot_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~YiChunHung/96.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 3\n",
    "plot_x = [\"term_\"+str(i) for i in count_vect.get_feature_names()[::100]]\n",
    "plot_y = [\"doc_\"+ str(i) for i in list(df.index)[::100]]\n",
    "plot_z = df_counts[::100, ::100].toarray()\n",
    "py.iplot(ta.plot_heat_map(plot_x, plot_y, plot_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "df_reduced = PCA(n_components=3).fit_transform(df_counts.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace1 = ta.get_trace(df_reduced, df[\"category_name\"], categories[0], \"rgb(71,233,163)\")\n",
    "trace2 = ta.get_trace(df_reduced, df[\"category_name\"], categories[1], \"rgb(52,133,252)\")\n",
    "trace3 = ta.get_trace(df_reduced, df[\"category_name\"], categories[2], \"rgb(229,65,136)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [trace1, trace2, trace3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~YiChunHung/90.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = go.Layout(\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='simple-3d-scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Atrribute Transformation / Aggregation\n",
    "\n",
    "# note this takes time to compute. You may want to reduce the amount of terms you want to compute frequencies for\n",
    "term_frequencies = []\n",
    "for j in range(0,df_counts.shape[1]):\n",
    "    term_frequencies.append(sum(df_counts[:,j].toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_frequencies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~YiChunHung/92.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(ta.plot_word_frequency([count_vect.get_feature_names(), term_frequencies], \"Term Frequency Distribution\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~YiChunHung/98.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 4\n",
    "# Sample for one out of ten\n",
    "data=[count_vect.get_feature_names()[::10], term_frequencies[::10]]\n",
    "py.iplot(ta.plot_word_frequency(data, \"Term Frequency Distribution\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~YiChunHung/102.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5\n",
    "sort_name = [x for _,x in sorted(zip(data[1],data[0]))]\n",
    "sort_freq = sorted(data[1])\n",
    "py.iplot(ta.plot_word_frequency([sort_name,sort_freq], \"Term Frequency Distribution\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "term_frequencies_log = [math.log(i) for i in term_frequencies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~YiChunHung/104.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(ta.plot_word_frequency([count_vect.get_feature_names(), term_frequencies_log], \"Term Frequency Distribution\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing, metrics, decomposition, pipeline, dummy\n",
    "mlb = preprocessing.LabelBinarizer()\n",
    "mlb.fit(df.category_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amazon_cells_labelled', 'imdb_labelled', 'yelp_labelled'],\n",
       "      dtype='<U21')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['bin_category'] = mlb.transform(df['category_name']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category_name</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bin_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I got food poisoning here at the buffet.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp_labelled</td>\n",
       "      <td>[I, got, food, poisoning, here, at, the, buffe...</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Always a great time at Dos Gringos!</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp_labelled</td>\n",
       "      <td>[Always, a, great, time, at, Dos, Gringos, !]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It holds a charge for a long time, is reasonab...</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon_cells_labelled</td>\n",
       "      <td>[It, holds, a, charge, for, a, long, time, ,, ...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was probably dirt.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp_labelled</td>\n",
       "      <td>[It, was, probably, dirt, .]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All things considered, a job very well done.</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb_labelled</td>\n",
       "      <td>[All, things, considered, ,, a, job, very, wel...</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What possesed me to get this junk, I have no i...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon_cells_labelled</td>\n",
       "      <td>[What, possesed, me, to, get, this, junk, ,, I...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>It's a fresh, subtle, and rather sublime effec...</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb_labelled</td>\n",
       "      <td>[It, 's, a, fresh, ,, subtle, ,, and, rather, ...</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AFTER ARGUING WITH VERIZON REGARDING THE DROPP...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon_cells_labelled</td>\n",
       "      <td>[AFTER, ARGUING, WITH, VERIZON, REGARDING, THE...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Excellent sound quality.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon_cells_labelled</td>\n",
       "      <td>[Excellent, sound, quality, .]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  \\\n",
       "0           I got food poisoning here at the buffet.     0   \n",
       "1                Always a great time at Dos Gringos!     1   \n",
       "2  It holds a charge for a long time, is reasonab...     1   \n",
       "3                              It was probably dirt.     0   \n",
       "4     All things considered, a job very well done.       1   \n",
       "5  What possesed me to get this junk, I have no i...     0   \n",
       "6  It's a fresh, subtle, and rather sublime effec...     1   \n",
       "7  AFTER ARGUING WITH VERIZON REGARDING THE DROPP...     0   \n",
       "8                           Excellent sound quality.     1   \n",
       "\n",
       "           category_name                                           unigrams  \\\n",
       "0          yelp_labelled  [I, got, food, poisoning, here, at, the, buffe...   \n",
       "1          yelp_labelled      [Always, a, great, time, at, Dos, Gringos, !]   \n",
       "2  amazon_cells_labelled  [It, holds, a, charge, for, a, long, time, ,, ...   \n",
       "3          yelp_labelled                       [It, was, probably, dirt, .]   \n",
       "4          imdb_labelled  [All, things, considered, ,, a, job, very, wel...   \n",
       "5  amazon_cells_labelled  [What, possesed, me, to, get, this, junk, ,, I...   \n",
       "6          imdb_labelled  [It, 's, a, fresh, ,, subtle, ,, and, rather, ...   \n",
       "7  amazon_cells_labelled  [AFTER, ARGUING, WITH, VERIZON, REGARDING, THE...   \n",
       "8  amazon_cells_labelled                     [Excellent, sound, quality, .]   \n",
       "\n",
       "  bin_category  \n",
       "0    [0, 0, 1]  \n",
       "1    [0, 0, 1]  \n",
       "2    [1, 0, 0]  \n",
       "3    [0, 0, 1]  \n",
       "4    [0, 1, 0]  \n",
       "5    [1, 0, 0]  \n",
       "6    [0, 1, 0]  \n",
       "7    [1, 0, 0]  \n",
       "8    [1, 0, 0]  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:9]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
